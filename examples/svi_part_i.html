

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>SVI Part I: An Introduction to Stochastic Variational Inference in Pyro &mdash; Pyro Tutorials  documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="Pyro Tutorials  documentation" href="index.html"/>
        <link rel="next" title="SVI Part II: Conditional Independence, Subsampling, and Amortization" href="svi_part_ii.html"/>
        <link rel="prev" title="Welcome to Pyro Tutorials’s documentation!" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Pyro Tutorials
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Model-Learning">Model Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Guide">Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ELBO">ELBO</a></li>
<li class="toctree-l2"><a class="reference internal" href="#SVI-Class"><code class="docutils literal"><span class="pre">SVI</span></code> Class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Optimizers">Optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#A-simple-example">A simple example</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Sample-output:">Sample output:</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: Conditional Independence, Subsampling, and Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="vae.html">Variational Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">Modeling Polyphonic Music with a Deep Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>SVI Part I: An Introduction to Stochastic Variational Inference in Pyro</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/svi_part_i.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="SVI-Part-I:-An-Introduction-to-Stochastic-Variational-Inference-in-Pyro">
<h1>SVI Part I: An Introduction to Stochastic Variational Inference in Pyro<a class="headerlink" href="#SVI-Part-I:-An-Introduction-to-Stochastic-Variational-Inference-in-Pyro" title="Permalink to this headline">¶</a></h1>
<p>Pyro has been designed with particular attention paid to supporting
stochastic variational inference as a general purpose inference
algorithm. Let’s see how we go about doing variational inference in
Pyro.</p>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this headline">¶</a></h2>
<p>We’re going to assume we’ve already defined our model in Pyro (for more
details on how this is done [<strong>SEE LINK</strong>]). As a quick reminder, the
model is given as a stochastic function <code class="docutils literal"><span class="pre">model(*args,</span> <span class="pre">**kwargs)</span></code>,
which, in the general case takes arguments. The different pieces of
<code class="docutils literal"><span class="pre">model()</span></code> are encoded via the mapping:</p>
<ol class="arabic simple">
<li>observations <span class="math">\(\Longleftrightarrow\)</span> <code class="docutils literal"><span class="pre">pyro.observe</span></code></li>
<li>latent random variables <span class="math">\(\Longleftrightarrow\)</span> <code class="docutils literal"><span class="pre">pyro.sample</span></code></li>
<li>parameters <span class="math">\(\Longleftrightarrow\)</span> <code class="docutils literal"><span class="pre">pyro.param</span></code></li>
</ol>
<p>Now let’s establish some notation. The model has observations
<span class="math">\({\bf x}\)</span> and latent random variables <span class="math">\({\bf z}\)</span> as well as
parameters <span class="math">\(\theta\)</span>. It has a joint probability density of the
form</p>
<div class="math">
\[p_{\theta}({\bf x}, {\bf z}) = p_{\theta}({\bf x}|{\bf z}) p_{\theta}({\bf z})\]</div>
<p>We assume that the various probability distributions <span class="math">\(p_i\)</span> that
make up <span class="math">\(p_{\theta}({\bf x}, {\bf z})\)</span> have the following
properties:</p>
<ol class="arabic simple">
<li>we can sample from each <span class="math">\(p_i\)</span></li>
<li>we can compute the pointwise log pdf <span class="math">\(p_i\)</span></li>
<li><span class="math">\(p_i\)</span> is differentiable w.r.t. the parameters <span class="math">\(\theta\)</span></li>
</ol>
</div>
<div class="section" id="Model-Learning">
<h2>Model Learning<a class="headerlink" href="#Model-Learning" title="Permalink to this headline">¶</a></h2>
<p>In this context our criterion for learning a good model will be
maximizing the log evidence, i.e.&nbsp;we want to find the value of
<span class="math">\(\theta\)</span> given by</p>
<div class="math">
\[\theta_{\rm{max}} = \underset{\theta}{\operatorname{argmax}} \log p_{\theta}({\bf x})\]</div>
<p>where the log evidence <span class="math">\(\log p_{\theta}({\bf x})\)</span> is given by</p>
<div class="math">
\[\log p_{\theta}(x) = \log \int\! d{\bf z}\; p_{\theta}({\bf x}, {\bf z})\]</div>
<p>In the general case this is a doubly difficult problem. This is because
(even for a fixed <span class="math">\(\theta\)</span>) the integral over the latent random
variables <span class="math">\(\bf z\)</span> is often intractable. Conversely, even if we
know how to calculate the log evidence for all values of <span class="math">\(\theta\)</span>,
maximizing the log evidence as a function of <span class="math">\(\theta\)</span> will in
general be a difficult non-convex optimization problem.</p>
<p>In addition to finding <span class="math">\(\theta_{\rm{max}}\)</span>, we would like to
calculate the posterior over the latent variables <span class="math">\(\bf z\)</span>:</p>
<div class="math">
\[ p_{\theta_{\rm{max}}}({\bf z} | {\bf x}) = \frac{p_{\theta_{\rm{max}}}({\bf x} , {\bf z})}{
\int \! d{\bf z}\; p_{\theta_{\rm{max}}}({\bf x} , {\bf z}) }\]</div>
<p>Note that the denominator of this expression is the (usually
intractable) evidence. Variational inference offers a scheme for finding
<span class="math">\(\theta_{\rm{max}}\)</span> and computing an approximation to the
posterior <span class="math">\(p_{\theta_{\rm{max}}}({\bf z} | {\bf x})\)</span>. Let’s see
how that works.</p>
</div>
<div class="section" id="Guide">
<h2>Guide<a class="headerlink" href="#Guide" title="Permalink to this headline">¶</a></h2>
<p>The basic idea is that we introduce a parameterized distribution
<span class="math">\(q_{\phi}({\bf z})\)</span>, where <span class="math">\(\phi\)</span> are known as the
variational parameters. This distribution is called the variational
distribution in most of the literature, and in the context of Pyro it’s
called the <strong>guide</strong> (one syllable instead of nine!). The guide will
serve as an approximation to the posterior.</p>
<p>Just like the model, the guide is encoded as a stochastic function
<code class="docutils literal"><span class="pre">guide()</span></code> that contains <code class="docutils literal"><span class="pre">pyro.sample</span></code> and <code class="docutils literal"><span class="pre">pyro.param</span></code> statements.
It does <em>not</em> contain <code class="docutils literal"><span class="pre">pyro.observe</span></code> statements, since the guide needs
to be a properly normalized distribution. Note that Pyro enforces that
<code class="docutils literal"><span class="pre">model()</span></code> and <code class="docutils literal"><span class="pre">guide()</span></code> have the same call signature, i.e.&nbsp;both
callables should take the same arguments.</p>
<p>Since the guide is an approximation to the posterior
<span class="math">\(p_{\theta_{\rm{max}}}({\bf z} | {\bf x})\)</span>, the guide needs to
provide a valid joint probability density over all the latent random
variables in the model. Recall that when random variables are specified
in Pyro with the primitive statement <code class="docutils literal"><span class="pre">pyro.sample()</span></code> the first
argument denotes the name of the random variable. These names will be
used to align the random variables in the model and guide. To be very
explicit, if the model contains a random variable <code class="docutils literal"><span class="pre">z_1</span></code></p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">model</span><span class="p">():</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;z_1&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>then the guide needs to have a matching <code class="docutils literal"><span class="pre">sample</span></code> statement</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">guide</span><span class="p">():</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;z_1&quot;</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>The distributions used in the two cases can be different, but the names
must line-up 1-to-1.</p>
<p>Once we’ve specified a guide (we give some explicit examples below),
we’re ready to proceed to inference. Learning will be setup as an
optimization problem where each iteration of training takes a step in
<span class="math">\(\theta-\phi\)</span> space that moves the guide closer to the exact
posterior. To do this we need to define an appropriate objective
function.</p>
</div>
<div class="section" id="ELBO">
<h2>ELBO<a class="headerlink" href="#ELBO" title="Permalink to this headline">¶</a></h2>
<p>A simple derivation (for example see reference [1]) yields what we’re
after: the evidence lower bound (ELBO). The ELBO, which is a function of
both <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span>, is defined as an expectation
w.r.t. to samples from the guide:</p>
<div class="math">
\[{\rm ELBO} \equiv \mathbb{E}_{q_{\phi}({\bf z})} \left [
\log p_{\theta}({\bf x}, {\bf z}) - \log q_{\phi}({\bf z})
\right]\]</div>
<p>By assumption we can compute the log probabilities inside the
expectation. And since the guide is assumed to be a parametric
distribution we can sample from, we can compute Monte Carlo estimates of
this quantity. Crucially, the ELBO is a lower bound to the log evidence,
i.e.&nbsp;for all choices of <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span> we have that</p>
<div class="math">
\[\log p_{\theta}({\bf x}) \ge {\rm ELBO}\]</div>
<p>So if we take (stochastic) gradient steps to maximize the ELBO, we will
also be pushing the log evidence higher (in expectation). Furthermore,
it can be shown that the gap between the ELBO and the log evidence is
given by the KL divergence between the guide and the posterior:</p>
<div class="math">
\[ \log p_{\theta}({\bf x}) - {\rm ELBO} =
\rm{KL}\!\left( q_{\phi}({\bf z}) \lVert p_{\theta}({\bf z} | {\bf x}) \right)\]</div>
<p>This KL divergence is a particular (non-negative) measure of ‘closeness’
between two distributions. So, for a fixed <span class="math">\(\theta\)</span>, as we take
steps in <span class="math">\(\phi\)</span> space that increase the ELBO, we decrease the KL
divergence between the guide and the posterior, i.e.&nbsp;we move the guide
towards the posterior. In the general case we take gradient steps in
both <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span> space simultaneously so that the
guide and model play chase, with the guide tracking a moving posterior
<span class="math">\(\log p_{\theta}({\bf z} | {\bf x})\)</span>. Perhaps somewhat
surprisingly, despite the moving target, this optimization problem can
be solved (to a suitable level of approximation) for many different
problems.</p>
<p>So at high level variational inference is easy: all we need to do is
define a guide and compute gradients of the ELBO. Actually, computing
gradients for general model and guide pairs leads to some complications
(see the tutorial <a class="reference external" href="svi_par_iii.html">SVI Part III</a> for a discussion).
For the purposes of this tutorial, let’s consider that a solved problem
and look at the support that Pyro provides for doing variational
inference.</p>
</div>
<div class="section" id="SVI-Class">
<h2><code class="docutils literal"><span class="pre">SVI</span></code> Class<a class="headerlink" href="#SVI-Class" title="Permalink to this headline">¶</a></h2>
<p>In Pyro the machinery for doing variational inference is encapsulated in
the <code class="docutils literal"><span class="pre">SVI</span></code> class. (At present <code class="docutils literal"><span class="pre">SVI</span></code> only provides support for the
ELBO objective, but in the future Pyro will provide support for
alternative variational objectives.)</p>
<p>The user needs to provide three things: the model, the guide, and an
optimizer. We’ve discussed the model and guide above and we’ll discuss
the optimizer in some detail below, so let’s assume we have all three
ingredients at hand. To construct an instance of <code class="docutils literal"><span class="pre">SVI</span></code> that will do
optimization via the ELBO objective, the user writes</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">SVI</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;ELBO&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">SVI</span></code> object provides two methods, <code class="docutils literal"><span class="pre">step()</span></code> and
<code class="docutils literal"><span class="pre">evaluate_loss()</span></code>, that encapsulate the logic for variational learning
and evaluation:</p>
<ol class="arabic simple">
<li>The method <code class="docutils literal"><span class="pre">step()</span></code> takes a single gradient step and returns an
estimate of the loss (i.e.&nbsp;minus the ELBO). If provided, the
arguments to <code class="docutils literal"><span class="pre">step()</span></code> are piped to <code class="docutils literal"><span class="pre">model()</span></code> and <code class="docutils literal"><span class="pre">guide()</span></code>.</li>
<li>The method <code class="docutils literal"><span class="pre">evaluate_loss()</span></code> returns an estimate of the loss
<em>without</em> taking a gradient step. Just like for <code class="docutils literal"><span class="pre">step()</span></code>, if
provided, arguments to <code class="docutils literal"><span class="pre">evaluate_loss()</span></code> are piped to <code class="docutils literal"><span class="pre">model()</span></code>
and <code class="docutils literal"><span class="pre">guide()</span></code>.</li>
</ol>
<p>For the case where the loss is the ELBO, both methods also accept an
optional argument <code class="docutils literal"><span class="pre">num_particles</span></code>, which denotes the number of samples
used to compute the loss (in the case of <code class="docutils literal"><span class="pre">evaluate_loss</span></code>) and the loss
and gradient (in the case of <code class="docutils literal"><span class="pre">step</span></code>). Note that <code class="docutils literal"><span class="pre">SVI</span></code> also provides
support for user-defined losses; see the documentation for details.</p>
</div>
<div class="section" id="Optimizers">
<h2>Optimizers<a class="headerlink" href="#Optimizers" title="Permalink to this headline">¶</a></h2>
<p>In Pyro, the model and guide are allowed to be arbitrary stochastic
functions provided that</p>
<ol class="arabic simple">
<li><code class="docutils literal"><span class="pre">guide</span></code> doesn’t contain any <code class="docutils literal"><span class="pre">pyro.observe</span></code> statements</li>
<li><code class="docutils literal"><span class="pre">model</span></code> and <code class="docutils literal"><span class="pre">guide</span></code> have the same call signature</li>
</ol>
<p>This presents some challenges because it means that different executions
of <code class="docutils literal"><span class="pre">model()</span></code> and <code class="docutils literal"><span class="pre">guide()</span></code> may have quite different behavior, with
e.g.&nbsp;certain latent random variables and parameters only appearing some
of the time. Indeed parameters may be created dynamically during the
course of inference. In other words the space we’re doing optimization
over, which is parameterized by <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span>, can
grow dynamically.</p>
<p>In order to support this behavior, Pyro needs to dynamically generate an
optimizer for each parameter the first time it appears during learning.
Luckily, PyTorch has a lightweight optimization library (see
<a class="reference external" href="http://pytorch.org/docs/master/optim.html">torch.optim</a>) that can
easily be repurposed for the dynamic case.</p>
<p>All of this is controlled by the <code class="docutils literal"><span class="pre">optim.PyroOptim</span></code> class, which is
basically a thin wrapper around PyTorch optimizers. <code class="docutils literal"><span class="pre">PyroOptim</span></code> takes
two arguments: a constructor for PyTorch optimizers
<code class="docutils literal"><span class="pre">optim_constructor</span></code> and a specification of the optimizer arguments
<code class="docutils literal"><span class="pre">optim_args</span></code>. At high level, in the course of optimization, whenever a
new parameter is seen <code class="docutils literal"><span class="pre">optim_constructor</span></code> is used to instantiate a new
optimizer of the given type with arguments given by <code class="docutils literal"><span class="pre">optim_args</span></code>.</p>
<p>Most users will probably not interact with <code class="docutils literal"><span class="pre">PyroOptim</span></code> directly and
will instead interact with the aliases defined in <code class="docutils literal"><span class="pre">optim/__init__.py</span></code>.
Let’s see how that goes. There are two ways to specify the optimizer
arguments. In the simpler case, <code class="docutils literal"><span class="pre">optim_args</span></code> is a <em>fixed</em> dictionary
that specifies the arguments used to instantiate PyTorch optimizers for
<em>all</em> the parameters:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">adam_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.005</span><span class="p">,</span> <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_params</span><span class="p">)</span>
</pre></div>
</div>
<p>The second way to specify the arguments allows for a finer level of
control. Here the user must specify a callable that will be invoked by
Pyro upon creation of an optimizer for a newly seen parameter. This
callable must have the following signature:</p>
<ol class="arabic simple">
<li><code class="docutils literal"><span class="pre">module_name</span></code>: the Pyro name of the module containing the
parameter, if any</li>
<li><code class="docutils literal"><span class="pre">param_name</span></code>: the Pyro name of the parameter</li>
<li><code class="docutils literal"><span class="pre">tags</span></code>: a (possibly empty) iterable of parameter tags</li>
</ol>
<p>This gives the user the ability to, for example, customize learning
rates for different parameters. For an example where this sort of level
of control is useful, see the <a class="reference external" href="svi_part_iii">discussion of
baselines</a>. Here’s a simple example to illustrate the
API:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="k">def</span> <span class="nf">per_param_callable</span><span class="p">(</span><span class="n">module_name</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;param_name&#39;</span> <span class="o">==</span> <span class="s1">&#39;my_special_parameter&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.010</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">per_param_callable</span><span class="p">)</span>
</pre></div>
</div>
<p>This simply tells Pyro to use a learning rate of <code class="docutils literal"><span class="pre">0.010</span></code> for the Pyro
parameter <code class="docutils literal"><span class="pre">my_special_parameter</span></code> and a learning rate of <code class="docutils literal"><span class="pre">0.001</span></code> for
all other parameters.</p>
</div>
<div class="section" id="A-simple-example">
<h2>A simple example<a class="headerlink" href="#A-simple-example" title="Permalink to this headline">¶</a></h2>
<p>We finish with a simple example. You’ve been given a two-sided coin. You
want to determine whether the coin is fair or not, i.e.&nbsp;whether it falls
heads or tails with the same frequency. You have a prior belief about
the likely fairness of the coin based on two observations:</p>
<ul class="simple">
<li>it’s a standard quarter issued by the US Mint</li>
<li>it’s a bit banged up from years of use</li>
</ul>
<p>So while you expect the coin to have been quite fair when it was first
produced, you allow for its fairness to have since deviated from a
perfect 1:1 ratio. So you wouldn’t be surprised if it turned out that
the coin preferred heads over tails at a ratio of 11:10. By contrast you
would be very surprised if it turned out that the coin preferred heads
over tails at a ratio of 5:1—it’s not <em>that</em> banged up.</p>
<p>To turn this into a probabilistic model we encode heads and tails as
<code class="docutils literal"><span class="pre">1</span></code>s and <code class="docutils literal"><span class="pre">0</span></code>s. We encode the fairness of the coin as a real
number <span class="math">\(f\)</span>, where <span class="math">\(f\)</span> satisfies <span class="math">\(f \in [0.0, 1.0]\)</span> and
<span class="math">\(f=0.50\)</span> corresponds to a perfectly fair coin. Our prior belief
about <span class="math">\(f\)</span> will be encoded by a beta distribution, specifically
<span class="math">\(\rm{Beta}(10,10)\)</span>, which is a symmetric probability distribution
on the interval <span class="math">\([0.0, 1.0]\)</span> that is peaked at <span class="math">\(f=0.5\)</span>.</p>
<figure><figcaption><p>Figure 1: The distribution <span class="math">\(\rm{Beta}(10,10)\)</span> that encodes our
prior belief about the fairness of the coin.</p>
</figcaption></figure><p>To learn something about the fairness of the coin that is more precise
than our somewhat vague prior, we need to do an experiment and collect
some data. Let’s say we flip the coin 10 times and record the result of
each flip. In practice we’d probably want to do more than 10 trials, but
hey this is a tutorial.</p>
<p>Assuming we’ve collected the data in a list <code class="docutils literal"><span class="pre">data</span></code>, the corresponding
model is given by</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="kn">as</span> <span class="nn">dist</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># define the hyperparameters that control the beta prior</span>
    <span class="n">alpha0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">]))</span>
    <span class="n">beta0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">]))</span>
    <span class="c1"># sample f from the beta prior</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent_fairness&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span><span class="p">)</span>
    <span class="c1"># loop over the observed data</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="c1"># observe datapoint i using the bernoulli</span>
        <span class="c1"># likelihood Bernoulli(f)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="s2">&quot;obs_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">,</span>
                     <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we have a single latent random variable (<code class="docutils literal"><span class="pre">'latent_fairness'</span></code>),
which is distributed according to <span class="math">\(\rm{Beta}(10, 10)\)</span>. Conditioned
on that random variable, we observe each of the datapoints using a
bernoulli likelihood. Note that each observation is assigned a unique
name in Pyro.</p>
<p>Our next task is to define a corresponding guide, i.e.&nbsp;an appropriate
variational distribution for the latent random variable <span class="math">\(f\)</span>. The
only real requirement here is that <span class="math">\(q(f)\)</span> should be a probability
distribution over the range <span class="math">\([0.0, 1.0]\)</span>, since <span class="math">\(f\)</span> doesn’t
make sense outside of that range. A simple choice is to use another beta
distribution parameterized by two trainable parameters <span class="math">\(\alpha_q\)</span>
and <span class="math">\(\beta_q\)</span>. Actually, in this particular case this is the
‘right’ choice, since conjugacy of the bernoulli and beta distributions
means that the exact posterior is a beta distribution. In Pyro we write:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># define the initial values of the two variational parameters</span>
    <span class="n">log_alpha_q_0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">15.0</span><span class="p">)]),</span>
                             <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">log_beta_q_0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">15.0</span><span class="p">)]),</span>
                            <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># register the two variational parameters with Pyro</span>
    <span class="n">log_alpha_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_alpha_q&quot;</span><span class="p">,</span> <span class="n">log_alpha_q_0</span><span class="p">)</span>
    <span class="n">log_beta_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_beta_q&quot;</span><span class="p">,</span> <span class="n">log_beta_q_0</span><span class="p">)</span>
    <span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_alpha_q</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_beta_q</span><span class="p">)</span>
    <span class="c1"># sample latent_fairness from the distribution</span>
    <span class="c1"># Beta(alpha_q, beta_q)</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent_fairness&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span><span class="p">)</span>
</pre></div>
</div>
<p>There are a few things to note here: - we’ve taken care that the names
of the random variables line up exactly between the model and guide -
<code class="docutils literal"><span class="pre">model(data)</span></code> and <code class="docutils literal"><span class="pre">guide(data)</span></code> take the same arguments - the
variational parameters are PyTorch <code class="docutils literal"><span class="pre">Variable</span></code>s with
<code class="docutils literal"><span class="pre">requires_grad=True</span></code>. if we forget to set the <code class="docutils literal"><span class="pre">requires_grad</span></code> flag
correctly, the parameters won’t be trained. - the variational parameters
are actually defined in log space. this is because we need <code class="docutils literal"><span class="pre">alpha_q</span></code>
and <code class="docutils literal"><span class="pre">beta_q</span></code> to be non-negative in order to define a valid beta
distribution.</p>
<p>Now we can proceed to do stochastic variational inference.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># set up the optimizer</span>
<span class="n">adam_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.0005</span><span class="p">,</span> <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_params</span><span class="p">)</span>

<span class="c1"># setup the inference algorithm</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;ELBO&quot;</span><span class="p">)</span>

<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="c1"># do gradient steps</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that in the <code class="docutils literal"><span class="pre">step()</span></code> method we pass in the data, which then get
passed to the model and guide.</p>
<p>The only thing we’re missing at this point is some data. So let’s create
some data and assemble all the code snippets above into a complete
script:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython2"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">SVI</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="kn">as</span> <span class="nn">dist</span>

<span class="c1"># clear the param store in case we&#39;re in a REPL</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>

<span class="c1"># create some data with 6 observed heads and 4 observed tails</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># define the hyperparameters that control the beta prior</span>
    <span class="n">alpha0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">]))</span>
    <span class="n">beta0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">10.0</span><span class="p">]))</span>
    <span class="c1"># sample f from the beta prior</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent_fairness&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span><span class="p">)</span>
    <span class="c1"># loop over the observed data</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="c1"># observe datapoint i using the bernoulli likelihood</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="s2">&quot;obs_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">guide</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="c1"># define the initial values of the two variational parameters</span>
    <span class="c1"># we initialize the guide near the model prior (except a bit sharper)</span>
    <span class="n">log_alpha_q_0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">15.0</span><span class="p">)]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">log_beta_q_0</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">15.0</span><span class="p">)]),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># register the two variational parameters with Pyro</span>
    <span class="n">log_alpha_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_alpha_q&quot;</span><span class="p">,</span> <span class="n">log_alpha_q_0</span><span class="p">)</span>
    <span class="n">log_beta_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_beta_q&quot;</span><span class="p">,</span> <span class="n">log_beta_q_0</span><span class="p">)</span>
    <span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_alpha_q</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_beta_q</span><span class="p">)</span>
    <span class="c1"># sample latent_fairness from Beta(alpha_q, beta_q)</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;latent_fairness&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span><span class="p">)</span>

<span class="c1"># setup the optimizer</span>
<span class="n">adam_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.0005</span><span class="p">,</span> <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)}</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_params</span><span class="p">)</span>

<span class="c1"># setup the inference algorithm</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;ELBO&quot;</span><span class="p">,</span> <span class="n">num_particles</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">4000</span>
<span class="c1"># do gradient steps</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="c1"># grab the learned variational parameters</span>
<span class="n">alpha_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_alpha_q&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">beta_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;log_beta_q&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># here we use some facts about the beta distribution</span>
<span class="c1"># compute the inferred mean of the coin&#39;s fairness</span>
<span class="n">inferred_mean</span> <span class="o">=</span> <span class="n">alpha_q</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha_q</span> <span class="o">+</span> <span class="n">beta_q</span><span class="p">)</span>
<span class="c1"># compute inferred standard deviation</span>
<span class="n">factor</span> <span class="o">=</span> <span class="n">beta_q</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha_q</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">alpha_q</span> <span class="o">+</span> <span class="n">beta_q</span><span class="p">))</span>
<span class="n">inferred_std</span> <span class="o">=</span> <span class="n">inferred_mean</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">based on the data and our prior belief, the fairness &quot;</span> <span class="o">+</span>
      <span class="s2">&quot;of the coin is </span><span class="si">%.3f</span><span class="s2"> +- </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">inferred_mean</span><span class="p">,</span> <span class="n">inferred_std</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-cyan-fg">  File </span><span class="ansi-green-fg">&#34;&lt;ipython-input-1-812f7c4629f6&gt;&#34;</span><span class="ansi-cyan-fg">, line </span><span class="ansi-green-fg">54</span>
<span class="ansi-red-fg">    print(&#39;.&#39;, end=&#39;&#39;)</span>
                  ^
<span class="ansi-red-fg">SyntaxError</span><span class="ansi-red-fg">:</span> invalid syntax

</pre></div></div>
</div>
<p>Notice that we pass <code class="docutils literal"><span class="pre">num_particles=7</span></code> to the <code class="docutils literal"><span class="pre">SVI</span></code> constructor so
that we use seven samples of the latent random variable <span class="math">\(f\)</span> to
form our Monte Carlo estimator of the ELBO and its gradient. This helps
stabilize the gradient estimates. We’ll describe another approach for
dealing with noisy gradient estimates in <a class="reference external" href="svi_part_iii.html">another
tutorial</a>.</p>
<div class="section" id="Sample-output:">
<h3>Sample output:<a class="headerlink" href="#Sample-output:" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div>based on the data and our prior belief, the fairness of the coin is
0.532 +- 0.090</div></blockquote>
<p>This estimate is to be compared to the exact posterior mean, which in
this case is given by <span class="math">\(16/30 = 0.5\bar{3}\)</span>. Note that the final
estimate of the fairness of the coin is in between the the fairness
preferred by the prior (namely <span class="math">\(0.50\)</span>) and the fairness suggested
by the raw empirical frequencies (<span class="math">\(6/10 = 0.60\)</span>).</p>
</div>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[1] <code class="docutils literal"><span class="pre">Automated</span> <span class="pre">Variational</span> <span class="pre">Inference</span> <span class="pre">in</span> <span class="pre">Probabilistic</span> <span class="pre">Programming</span></code>,
&nbsp;&nbsp;&nbsp;&nbsp; David Wingate, Theo Weber</p>
<p>[2] <code class="docutils literal"><span class="pre">Black</span> <span class="pre">Box</span> <span class="pre">Variational</span> <span class="pre">Inference</span></code>,&nbsp;&nbsp;&nbsp;&nbsp; Rajesh Ranganath, Sean
Gerrish, David M. Blei</p>
<p>[3] <code class="docutils literal"><span class="pre">Auto-Encoding</span> <span class="pre">Variational</span> <span class="pre">Bayes</span></code>,&nbsp;&nbsp;&nbsp;&nbsp; Diederik P Kingma, Max
Welling</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="svi_part_ii.html" class="btn btn-neutral float-right" title="SVI Part II: Conditional Independence, Subsampling, and Amortization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Welcome to Pyro Tutorials’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Uber AI Labs.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>